\documentclass[mathserif]{beamer}

\usepackage{nips15}

%-----------------------------------------------------------------------
\usepackage{pdfpages}
\usepackage{array}
\usepackage{booktabs}
\usepackage[skins,breakable]{tcolorbox}
\usepackage{minibox}
\usepackage{mathtools}

\newcommand{\qcite}[1]{{\scriptsize\color{col2}[#1]}}

\newcommand{\qbox}[1]{%
\begin{tcolorbox}[enhanced jigsaw,size=tight,hbox,boxsep=4pt,boxrule=1pt,coltext=black,colframe=col1light,colback=col1,opacityback=0.7,opacityframe=1]
\strut #1
\end{tcolorbox}%
}

\newcommand{\qboxa}[1]{%
\begin{tcolorbox}[enhanced jigsaw,size=tight,hbox,boxsep=4pt,boxrule=1pt,coltext=textcolor,colframe=col1,opacityback=0,opacityframe=1]
\strut #1
\end{tcolorbox}%
}

\newcommand{\qboxb}[1]{%
\begin{tcolorbox}[enhanced jigsaw,size=tight,hbox,boxsep=4pt,boxrule=1pt,coltext=textcolor,colframe=col2,opacityback=0,opacityframe=1]
\strut #1
\end{tcolorbox}%
}

\newcommand{\qtheorem}[1]{%
\begin{tcolorbox}[enhanced jigsaw,size=tight,boxsep=7pt,boxrule=0.7pt,coltext=textcolor,colframe=col2,colback=col1,opacityback=0,opacityframe=1]
\begin{minipage}{\textwidth}
{\color{col2}\strut Theorem}\\[0.7em]
#1
\end{minipage}
\end{tcolorbox}%
}

\newcommand{\qlemma}[1]{%
\begin{tcolorbox}[enhanced jigsaw,size=tight,boxsep=7pt,boxrule=0.7pt,coltext=textcolor,colframe=col2,colback=col1,opacityback=0,opacityframe=1]
\begin{minipage}{\textwidth}
{\color{col2}\strut Lemma}\\[0.7em]
#1
\end{minipage}
\end{tcolorbox}%
}
%-----------------------------------------------------------------------

\title[Sampling from Probabilistic Submodular Models]
{Sampling from Probabilistic Submodular Models}

\author[Alkis Gotovos]{}

\begin{document}

\setbeamertemplate{background canvas}{}
\includepdf[pages={1}]{title.pdf}
\setbeamertemplate{background canvas}{\includegraphics[width=\paperwidth]{figures/bg.png}}

\begin{frame}{Image Collection Summarization}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/flickr_probs_0.png}
\end{frame}

\begin{frame}{Submodularity}
\vspace{0.5em}
\begin{itemize}
\item<1-> Facility location objective \qcite{Lin and Bilmes, '12} \qcite{Tschiatschek et al., '14}
\vspace{0.5em}
\item<2-> Encourage coverage and diversity of the summary
\vspace{0.5em}
\item<3-> Set of all images $V$
\vspace{0.5em}
\item<4-> For any summary $S \subseteq V\ \ \longrightarrow\ \ F(S) \in \mathbb{R}$
\end{itemize}

\vspace{0.5em}
\centering
\uncover<5->{\includegraphics[width=2.75in]{figures/submod_1.pdf}}
\end{frame}

\begin{frame}{Submodularity}
\vspace{0.5em}
\begin{itemize}
\item Facility location objective \qcite{Lin and Bilmes, '12} \qcite{Tschiatschek et al., '14}
\vspace{0.5em}
\item Encourage coverage and diversity of the summary
\vspace{0.5em}
\item Set of all images $V$
\vspace{0.5em}
\item For any summary $S \subseteq V\ \ \longrightarrow\ \ F(S) \in \mathbb{R}$
\end{itemize}

\vspace{0.5em}
\centering
\includegraphics[width=2.75in]{figures/submod_2.pdf}
\end{frame}

\begin{frame}{Submodularity}
\vspace{0.5em}
\begin{itemize}
\item Facility location objective \qcite{Lin and Bilmes, '12} \qcite{Tschiatschek et al., '14}
\vspace{0.5em}
\item Encourage coverage and diversity of the summary
\vspace{0.5em}
\item Set of all images $V$
\vspace{0.5em}
\item For any summary $S \subseteq V\ \ \longrightarrow\ \ F(S) \in \mathbb{R}$
\end{itemize}

\vspace{0.5em}
\centering
\includegraphics[width=2.75in]{figures/submod_3.pdf}
\end{frame}

\begin{frame}{Submodularity}
\vspace{0.5em}
\begin{tabular}{c*{2}{@{\hspace{3em}}c}}
$F$ is submodular & $\Longleftrightarrow$ & $-F$ is supermodular\\[0.5em]
$\downarrow$ & & $\downarrow$\\[0.5em]
\qboxa{coverage / diversity} & & \qboxb{smoothness / cooperation}
\end{tabular}

\vspace{2em}
\begin{itemize}
\item Submodular optimization is well-studied
\vspace{1em}
\item Little existing work on probabilistic models
\end{itemize}
%\centering
%\qbox{
%\minibox{Large amount of work on submodular optimization,\\but very little on probabilistic models.}
%}
\end{frame}

\begin{frame}{Interactive Summarization}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/flickr_probs_1_1.png}
\end{frame}

\begin{frame}{Interactive Summarization}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/flickr_probs_1_2.png}
\end{frame}

\begin{frame}{Interactive Summarization}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/flickr_probs_2_1.png}
\end{frame}

\begin{frame}{Interactive Summarization}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/flickr_probs_2_2.png}
\end{frame}

\begin{frame}{Foreground / Background Segmentation}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee.jpg}

\column{0.5\textwidth}
\uncover<2->{
\centering
\includegraphics[width=1.85in]{figures/bee_truth.png}
}
\end{columns}
\end{frame}

\begin{frame}{Foreground / Background Segmentation}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee.jpg}

\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee_dr1.png}
\end{columns}
\end{frame}

\begin{frame}{Pairwise Models}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee.jpg}

\column{0.5\textwidth}
\includegraphics[width=1.7in]{figures/grid.pdf}

\vspace{1em}
\begin{itemize}
\item Set of all pixels $V$
\vspace{1em}
\item For $S \subseteq V$ of foreground pixels,
\begin{align*}
F(S) = \sum_{v \sim w} F_{v, w}(S)
\end{align*}
\end{itemize}
\end{columns}
\end{frame}

\begin{frame}{Higher-order Models}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\only<1-2,6>{\includegraphics[width=1.85in]{figures/bee_superpixels.png}}
\only<3-5>{\includegraphics[width=1.85in]{figures/bee_superpixels_hl_v1.pdf}}
\column{0.5\textwidth}
\uncover<2->{
$V = V_1 \cup V_2 \cup \cdots \cup V_L$
}

\uncover<4->{
\vspace{1em}
$F_i(S) = \phi\left(|S \cap V_i|\right)$
}

\uncover<5->{
\vspace{1.3em}
\hspace{-1.5em}\includegraphics[width=2.1in]{figures/convex_over_modular.pdf}
}

\uncover<6->{
\vspace{1em}
$F(S) = \displaystyle\sum_{i=1}^L F_i(S)$
}
\end{columns}
\end{frame}

\begin{frame}{Higher-order Models \qcite{Djolonga and Krause, '15}}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee_dr1.png}

\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee_marginals.png}
\end{columns}
\end{frame}

\begin{frame}{Probabilistic Submodular Models}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/psm.pdf}

\vspace{0.5em}
\qboxa{$p(S) = \displaystyle\frac{1}{Z} \exp(F(S))$} $F : 2^V \to \mathbb{R}$ is a submodular or supermodular function
\end{frame}

\begin{frame}{Probabilistic Submodular Models}
\vspace{0.5em}
\centering
\includegraphics[width=4.2in]{figures/psm.pdf}

\vspace{0.5em}
\qboxa{$p(S) = \displaystyle\frac{1}{Z} \exp(F(S))$} $F : 2^V \to \mathbb{R}$ is a submodular or supermodular function
\end{frame}

\begin{frame}{Probabilistic Submodular Models}
\vspace{1em}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{>{\arraybackslash}p{0.47\textwidth}>{\arraybackslash}p{0.45\textwidth}}
\centering\arraybackslash {\large Prob. Submodular Models} & \centering\arraybackslash {\large \minibox{Markov Random Fields\\[0.2em]}}\\ \toprule

\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item Ground set $V$ with $|V| = n$
\end{itemize}
\end{minipage}
&
\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item Binary random vector

\vspace{0.7em}
\hspace{1em}$\mathcal{X} = (X_1, \ldots, X_n)$

\vspace{0.5em}
\end{itemize}
\end{minipage}\\

\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item $F : 2^V \to \mathbb{R}$
\end{itemize}
\end{minipage}
&
\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item Set of factors $\phi_i : \mathcal{X}_i \to \mathbb{R}$

\vspace{0.7em}
\end{itemize}
\end{minipage}\\

\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item Distribution over subsets

\vspace{1em}
$p(S) = \displaystyle\frac{1}{Z} \exp(F(S))$
\end{itemize}
\end{minipage}
&
\begin{minipage}[t]{\textwidth}
\begin{itemize}
\item Distribution over binary vectors

\vspace{0.3em}
$p(X) = \displaystyle\frac{1}{Z} \exp\left(\sum_i \phi_i(X_i)\right)$
\end{itemize}

\vspace{0.5em}
\end{minipage}\\ \midrule
\end{tabular}

\vspace{0.2em}
\centering
\qboxa{Model order: $\max_i |\mathcal{X}_i|$}
\end{frame}

\input{venn}

\begin{frame}{Inference}
\vspace{1em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
$\mathbb{P}(\textrm{pixel label} \mid \textrm{annotated pixels})$

\vspace{0.7em}
\centering
\includegraphics[width=1.75in]{figures/bee_marginals.png}

\column{0.5\textwidth}
\centering
$\mathbb{P}(\textrm{image} \in \textrm{summary} \mid \textrm{selected})$

\vspace{0.7em}
\centering
\includegraphics[width=1.75in]{figures/flickr_probs_1_1_portrait.png}
\vspace{2.85em}
\end{columns}
\end{frame}

\begin{frame}{Inference}
\vspace{0.5em}
\begin{columns}[c]
\column{0.3\textwidth}
\begin{minipage}[t][1.7em]{\textwidth}
\centering
Exact inference
\end{minipage}

\centering
\includegraphics[width=1.4in]{figures/inf01_exact.pdf}

\vspace{1em}
\begin{itemize}
\item \small{Tractable only for specific subclasses}
\vspace{1em}
\item \#P-hard even for Ising models
\end{itemize}

\column{0.3\textwidth}
\begin{minipage}[t][1.7em]{\textwidth}
\centering
BP, Mean-field, \ldots
\end{minipage}

\centering
\includegraphics[width=1.4in]{figures/inf02_loworder.pdf}

\vspace{1em}
\begin{itemize}
\item \small{Extensively studied problem}
\vspace{1em}
\item \small{Exponential in model order}
\end{itemize}

\column{0.3\textwidth}
\begin{minipage}[t][1.7em]{\textwidth}
\centering
L-\textsc{Field}
\end{minipage}

\centering
\includegraphics[width=1.4in]{figures/inf03_psm.pdf}

\vspace{1em}
\begin{itemize}
\item \small{Variational approach for general PSMs} \qcite{Djolonga and Krause, '14}
\vspace{1.2em}
\end{itemize}
\end{columns}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\begin{tabular}{*{2}{@{}l}}
\begin{minipage}{0.45\textwidth}
\begin{itemize}
\item State space $\Omega$
\end{itemize}
\end{minipage} & \color{col1}powerset of $V$\\[1em]
\begin{minipage}{0.45\textwidth}
\begin{itemize}
\item Transition matrix $P$
\end{itemize}
\end{minipage} & \color{col1}Gibbs sampler
\end{tabular}

\vspace{3em}
Define Markov chain $\left(X_t\right)_{t \geq 0}$ that moves according to $P$

\vspace{2em}
\begin{tabular}{*{2}{@{}l}}
\begin{minipage}{0.45\textwidth}
\begin{itemize}
\item Stationary distribution $\pi$
\end{itemize}
\end{minipage} & \color{col1}PSM distribution
\end{tabular}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\vspace{0.5em}
\centering
\includegraphics[height=3in]{figures/lattice_nodes_only.pdf}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\vspace{0.5em}
\centering
\includegraphics[height=3in]{figures/lattice_example_node.pdf}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\vspace{0.5em}
\centering
\includegraphics[height=3in]{figures/lattice_example_edges.pdf}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\vspace{0.5em}
\centering
\includegraphics[height=3in]{figures/lattice_full.pdf}
\end{frame}

\begin{frame}{Markov Chain Monte Carlo}
\vspace{0.5em}
\centering
\includegraphics[height=3in]{figures/lattice_full_binary.pdf}
\end{frame}

\begin{frame}{Gibbs Sampler for PSMs}
\vspace{1em}
Start at $X_0$

\vspace{1.1em}
For $t = 1, 2, \ldots$
\vspace{1.1em}
\begin{itemize}
\item Select random $v \in V$
\vspace{1.1em}
\item $\Delta \leftarrow F(X_t \cup \{v\}) - F(X_t \setminus \{v\})$
\vspace{1.1em}
\item $p_{\textrm{add}} \leftarrow e^{\beta \Delta} / \left(1 + e^{\beta \Delta}\right)$
\vspace{1.1em}
\item Flip biased coin

\vspace{-1em}
\begin{minipage}{0.5\textwidth}\vspace{2em}\includegraphics[width=2.7in]{figures/gibbs.pdf}\end{minipage}
\end{itemize}
\end{frame}

\begin{frame}{Mixing time}
\vspace{1em}
Total variation distance
\only<1>{
\begin{align*}
d(t) = d_{\mathrm{tv}}\left(\mathbb{P}_{X_t}, \pi\right)
\end{align*}}
\only<2>{
\begin{align*}
d(t) = {\color{col1}\max \{}d_{\mathrm{tv}}\left(\mathbb{P}_{X_t}, \pi\right) {\color{col1}\mid X_0 \in \Omega\}}
\end{align*}
}
\uncover<3->{
\begin{align*}
d(t) = \max \{d_{\mathrm{tv}}\left(\mathbb{P}_{X_t}, \pi\right) \mid X_0 \in \Omega\}
\end{align*}
}

\uncover<3->{
\vspace{1em}
Under mild assumptions (ergodicity),
\begin{align*}
d(t) \xrightarrow{\ t\,\rightarrow\,\infty\ } 0
\end{align*}
}

\uncover<4->{
\qboxa{How long does it take to get ``close enough" to $\pi$?}
}

\uncover<5->{
\vspace{1em}
Mixing time
\begin{align*}
t_{\textrm{mix}}(\epsilon) = \min \left\{t \mid d(t) \leq \epsilon \right\}
\end{align*}
}
\end{frame}

\begin{frame}{Goal}
\begin{itemize}
\item Mixing times for general PSMs are exponential in $|V|$
\vspace{1em}
\item Exponential even for pairwise models \qcite{Jerrum and Sinclair, '93}
\end{itemize}
\vspace{3em}
\centering
\qbox{\minibox{We establish sufficient conditions for sub-exponential mixing\\of the Gibbs sampler on PSMs.}}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\vspace{0.5em}
\includegraphics[width=3.9in,trim=5 0 0 0,clip]{figures/ineq_mod.pdf}

\vspace{4em}
``Distance" from modularity
\begin{align*}
\zeta_F \coloneqq \max_{A, B \subseteq V} \big|F(A) + F(B) - F(A \cup B) - F(A \cap B)\big|
\end{align*}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\qtheorem{
For any set function $F$, the mixing time of the Gibbs sampler is bounded by
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq 2n^2 \exp(2\beta\zeta_F)\log\left(\displaystyle\frac{1}{\epsilon p_{\textrm{min}}}\right).
\end{align*}
}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\vspace{0.5em}
\includegraphics[width=3.9in]{figures/decomp.pdf}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\qtheorem{
For any set function $F$, the mixing time of the Gibbs sampler is bounded by
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq 2n^2 \exp(2\beta\zeta_F)\log\left(\displaystyle\frac{1}{\epsilon p_{\textrm{min}}}\right).
\end{align*}

\vspace{0.5em}
If $F$ is submodular or supermodular the bound is improved to
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq 2n^2 \exp(\beta\zeta_f)\log\left(\displaystyle\frac{1}{\epsilon p_{\textrm{min}}}\right).
\end{align*}
}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\qtheorem{
For any set function $F$, the mixing time of the Gibbs sampler is bounded by
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq 2n^2 \exp({\color{col1}2}\beta\zeta_{\color{col1}F})\log\left(\displaystyle\frac{1}{\epsilon p_{\textrm{min}}}\right).
\end{align*}

\vspace{0.5em}
If $F$ is submodular or supermodular the bound is improved to
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq 2n^2 \exp(\beta\zeta_{\color{col1}f})\log\left(\displaystyle\frac{1}{\epsilon p_{\textrm{min}}}\right).
\end{align*}
}
\end{frame}

\begin{frame}{Polynomial-time Mixing}
\vspace{0.5em}
\begin{columns}[c]
\column{0.5\textwidth}
\centering
\includegraphics[width=1.85in]{figures/bee_superpixels.png}
\column{0.5\textwidth}
$F_i(S) = \phi\left(|S \cap V_i|\right)$

\vspace{1em}
$F(S) = \displaystyle\sum_{i=1}^L F_i(S)$

\vspace{3em}
$\zeta_F \leq L \phi_{\textrm{max}}$

\vspace{3em}
\centering
\qboxa{
$|V_i| \approx 10^5\ $ vs. $\ L \approx 50$
}
\end{columns}
\end{frame}

\begin{frame}{Fast Mixing}
Marginal gain
\begin{align*}
\Delta_F(v \mid S) \coloneqq F(S \cup \{v\}) - F(S)
\end{align*}

\vspace{1em}
Influence of $r \in V$ on $v \in V$
\begin{align*}
\gamma_F(v; r \mid S) \coloneqq \big|\Delta_F(v \mid S) - \Delta_F(v \mid S \cup \{r\})\big|
\end{align*}

\vspace{1em}
Maximum total influence :\hspace{0.5em} $\gamma_F$
\end{frame}

\begin{frame}{Fast Mixing}
\only<1>{
\qtheorem{
For any set function $F$, if $\gamma_F < 1$, the mixing time of the Gibbs sampler is bounded by
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq \frac{1}{1 - \gamma_F} n \left(\log n + \log \frac{1}{\epsilon}\right).
\end{align*}
}
}
\only<2>{
\qtheorem{
For any {\color{col1}submodular or supermodular} set function $F$, if $\gamma_{\color{col1}f} < 1$, the mixing time of the Gibbs sampler is bounded by
\vspace{-0.5em}
\begin{align*}
t_{\textrm{mix}}(\epsilon) \leq \frac{1}{1 - \gamma_{\color{col1}f}} n \left(\log n + \log \frac{1}{\epsilon}\right).
\end{align*}
}
}

\vspace{1em}
\begin{itemize}
\item Closely related to Dobrushin uniqueness conditions, and influence matrix norms \qcite{Dyer et al., '09}
\vspace{1em}
\item Similar theorem by \qcite{Rebeschini and Karbasi, '15}
\end{itemize}
\end{frame}

\begin{frame}{Fast Mixing}
Decomposable functions
\begin{align*}
F(S) = \sum_{i = 1}^L F_i(S) \quad \longrightarrow \quad f(S) = \sum_{i = 1}^L f_i(S)
\end{align*}

Define
\begin{align*}
\theta_f \coloneqq \max_{v \in V} \sum_{i \in [L]} \sqrt{f_i(v)} \quad \textrm{and} \quad \lambda_f \coloneqq \max_{i \in [L]} \sum_{v \in V} \sqrt{f_i(v)}
\end{align*}

\qlemma{
For any decomposable submodular function $F$,
\vspace{-0.5em}
\begin{align*}
\gamma_f \leq \frac{\beta}{2}\theta_f \lambda_f.
\end{align*}
}
\end{frame}

\begin{frame}{Evaluation}
\vspace{0.5em}
\begin{itemize}
\item Compare against variational approach \qcite{Djolonga and Krause, '14}
\vspace{1.5em}
\item Three models with $|V| = 20$
\vspace{1.5em}
\item Here : facility location model (log-submodular)
\vspace{1.5em}
\item Compute marginals $p(v \mid S)$ for all $v \in V \setminus S$
\vspace{1.5em}
\item Start with $S = \varnothing$ and progressively increase it
\end{itemize}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_0.pdf}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_1.pdf}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_2.pdf}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_3.pdf}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_4.pdf}
\end{frame}

\begin{frame}{Evaluation}
\vspace{1em}
\centering
\includegraphics[width=4.15in,trim=6 0 0 0,clip]{figures/floc_5.pdf}
\end{frame}

\end{document}
